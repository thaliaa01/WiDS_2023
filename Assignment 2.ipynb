{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b26983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "C:\\Users\\singa\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 5.648567830046001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 20.74557616652671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 20.028478107804627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 20.777541056985793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 20.444899746228607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 20.64514241413806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 20.772606946072212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 20.719154077841768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 20.6788588387142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 20.752459326508426\n",
      "Accuracy on test set: 0.09092857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singa\\AppData\\Local\\Temp\\ipykernel_15044\\2566967972.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist.data.astype('float32'), mnist.target.astype('int')\n",
    "X /= 255.0\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(y.to_numpy().reshape(-1, 1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
    "input_size = 784\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "weights = {\n",
    "    'W1': np.random.randn(input_size, hidden_size1),\n",
    "    'W2': np.random.randn(hidden_size1, hidden_size2),\n",
    "    'W3': np.random.randn(hidden_size2, output_size),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': np.zeros((1, hidden_size1)),\n",
    "    'b2': np.zeros((1, hidden_size2)),\n",
    "    'b3': np.zeros((1, output_size)),\n",
    "}\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-10)) / m\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X_train, weights['W1']) + biases['b1']\n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    z2 = np.dot(a1, weights['W2']) + biases['b2']\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    z3 = np.dot(a2, weights['W3']) + biases['b3']\n",
    "    a3 = softmax(z3)\n",
    "    \n",
    "    loss = cross_entropy_loss(y_train, a3)\n",
    "   \n",
    "    dz3 = a3 - y_train\n",
    "    dw3 = np.dot(a2.T, dz3)\n",
    "    db3 = np.sum(dz3, axis=0, keepdims=True)\n",
    "    \n",
    "    dz2 = np.dot(dz3, weights['W3'].T) * (a2 * (1 - a2))\n",
    "    dw2 = np.dot(a1.T, dz2)\n",
    "    db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "    \n",
    "    dz1 = np.dot(dz2, weights['W2'].T) * (a1 * (1 - a1))\n",
    "    dw1 = np.dot(X_train.T, dz1)\n",
    "    db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "    \n",
    "    weights['W1'] -= learning_rate * dw1\n",
    "    biases['b1'] -= learning_rate * db1\n",
    "    \n",
    "    weights['W2'] -= learning_rate * dw2\n",
    "    biases['b2'] -= learning_rate * db2\n",
    "    \n",
    "    weights['W3'] -= learning_rate * dw3\n",
    "    biases['b3'] -= learning_rate * db3\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss}\")\n",
    "\n",
    "z1_test = np.dot(X_test, weights['W1']) + biases['b1']\n",
    "a1_test = sigmoid(z1_test)\n",
    "\n",
    "z2_test = np.dot(a1_test, weights['W2']) + biases['b2']\n",
    "a2_test = sigmoid(z2_test)\n",
    "\n",
    "z3_test = np.dot(a2_test, weights['W3']) + biases['b3']\n",
    "a3_test = softmax(z3_test)\n",
    "\n",
    "predictions = np.argmax(a3_test, axis=1)\n",
    "actual_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "accuracy = np.mean(predictions == actual_labels)\n",
    "print(f\"Accuracy on test set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b55f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
